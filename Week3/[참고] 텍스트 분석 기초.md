# 1. 텍스트 분석 기본 용어 정리

## 1. 토큰화 (Tokenization)

주어진 데이터를 **토큰**을 기준으로 나누는 것.

토큰의 기준을 단어로 하는 경우 단어 토큰화.

## 2. 불용어 (Stopword)

유의미한 단어 토큰만을 선별하기 위해서는 **큰 의미가 없는 단어 토큰**을 제거

## 3. 정규표현식 (Regular Expression) 문법

```python
import re
```

### 1) 특수문자

**.** : 한 개의 임의의 문자 (\n 제외)

**?** : 앞의 문자 0개 or 1개

***** : 앞의 문자 0개 이상

**+** : 앞의 문자 1개 이상

**^** : 뒤의 문자로 시작

**$** : 앞의 문자로 끝

**{숫자}** : 숫자만큼 반복

**{숫자1, 숫자2}** : 숫자1 이상, 숫자2 이하 반복. (?,*,+로 대체 가능)

**{숫자, }** : 숫자 이상만큼 반복

**[]** : 대괄호 안의 문자들 중 한개의 문자와 매치 ([a-z] : a부터 z까지 범위 지정)

**[^문자]** : 해당 문자를 제외한 문자

A **|** B : A 또는 B의 의미를 가짐.

**\\** : 역슬래쉬 문자 자체

**\d** : 모든 숫자 의미 [0-9]

**\D** : 숫자를 제외한 모든 문자 [^0-9]

**\s** : 공백 [\t\n\r\f\v]

**\S** : 공백을 제외한 문자 [^\t\n\r\f\v]

**\w** : 문자 or 숫자 [a-zA-Z0-9]

**\W** : 문자 or 숫자가 아닌 문자 [^a-zA-Z0-9]

### 2) 정규표현식 모듈 함수

- re.split() : 정규 표현식을 기준으로 문자열들을 분리 → 리스트로 리턴

```python
re.split("""정규 표현식""", text)
```

- re.findall() : 정규 표현식과 **매치되는 모든** 문자열들 리스트로 리턴 (매치되는 문자열 없으면 빈 리스트 리턴)

```python
re.findall("""정규 표현식""", text)
```

- re.sub() : 정규 표현식 패턴과 일치하는 문자열을 찾아 다른 문자열로 대체 가능

```python
re.sub('[^a-zA-Z]', ' ', text)      # 알파벳이 아닌 문자 --> ' '로 대체
```

## 4. 정수 인코딩(Integer Encoding)

컴퓨터는 텍스트보다는 숫자를 더 잘 처리. 텍스트 —> 숫자로 바꾸는 작업 필요

각 단어를 고유한 정수에 **맵핑(mapping)**

[위키독스](https://wikidocs.net/31766)

## 5. 패딩 (Padding)

각 문장(또는 문서)은 서로 길이가 다름.

병렬 연산을 위해서 여러 **문장의 길이를 임의로 동일**하게 맞춰주는 작업이 필요.

가장 긴 문장 길이에 맞춰 나머지 문장의 빈 부분을 0으로 채움.

## 6. 원-핫 인코딩 (One-Hot Encoding)

단어 집합의 크기 == 벡터의 차원

**표현하고 싶은 단어의 인덱스에 1**의 값을 부여하고, 다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식

정수 인코딩 —> 각 단어 정수 인코딩된 정수를 **인덱스**로 생각

## 7. Bag of Words (BoW)

단어들의 순서는 전혀 고려하지 않고, 단어들의 **출현 빈도**(frequency)에만 집중.

정수 인덱스 —> 각 인덱스의 위치에 **단어 토큰의 등장 횟수**를 기록한 벡터

# 2. 텍스트 분석 전처리

1. Text 변수에 저장

```python
text = """Twinkle, twinkle, little star
How I wonder what you are
Up above the world so high
Like a diamond in the sky
Twinkle, twinkle little star
How I wonder what you are
When the blazing sun is gone
When he nothing shines upon
Then you show your little light
Twinkle, twinkle, all the night
Twinkle, twinkle, little star
How I wonder what you are"""
```

  2.  토큰화

```python
tokenizedText = text.lower().split()       # 띄어쓰기 기준으로 나눔
```

  3.  불용어 제거

```python
stopwords = ['a', 'an', 'the', ... ]
noStopword = []
for word in tokenizedText:
	if word not in stopwords:
		noStopword.append(word)
```

  4.  빈도수 리스트 만들기

```python
wordDict = {}
for token in noStopword:
	if token not in wordDict:
		wordDict[token] = 1
	else:
		wordDict[token] += 1
```

  5.  워드 클라우드 이미지 생성

```python
from wordcloud import WordCloud
wordcloud = WordCloud().generate_from_frequencies(wordDict)
```

  6.  워드 클라우드 출력

```python
import matplotlib.pyplot as plt
plt.axis("off")
plt.imshow(wordcloud)
```
