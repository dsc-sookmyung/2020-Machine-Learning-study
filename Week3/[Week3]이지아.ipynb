{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\[Week3] 텍스트분석 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 텍스트 분석 기본 용어 정리\n",
    "https://wikidocs.net/21694  \n",
    "위의 링크와 구글링으로 정리  \n",
    "용어 정리는 추후에 본인이 보기에 편한 형식으로 정리하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 토큰화 (Tokenization)  \n",
    "\\[답변] 주어진 코퍼스(corpus)에서 토큰(token)이라 불리는 단위로 나누는 작업보통 의미있는 단위로 토큰을 정의한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 불용어 (Stopword)  \n",
    "\\[답변]  자주 등장하지만 분석을 하는 것에 있어서는 큰 도움이 되지 않는 단어들 ex) 조사, 접미사 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 정규표현식 (Regular Expression) 문법  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 정규 표현식에 해당하는 스트링 2개 이상  \n",
    "(1) a+  \n",
    "\\[답변] 반복을 표현하며 a 문자가 한번 이상 반복됨을 의미한다.\n",
    "<br>\n",
    "(2) a{3}b{2,}  \n",
    "\\[답변] 반복을 표현하며 a 문자가 3번 반복, b 문자가 2번 이상 반복됨을 의미한다\n",
    "<br> \n",
    "(3) .+b$  \n",
    "\\[답변] b로 끝나야되는데, b앞에 1개 이상의 알파벳이 있어야된다. \n",
    "<br>\n",
    "(4) ^ab*  \n",
    "\\[답변] ab로 시작하는 단어들 모두\n",
    "<br>\n",
    "(5) \\[a-z]+\\[^a|z]  \n",
    "\\[답변] a-z 사이의 알파벳 중 a와z는 아닌 것 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 정규 표현식 문자 규칙 의미  \n",
    "(1) \\\\\\ \\[답변] 역슬래쉬 문자 자체를 의미함\n",
    "<br>\n",
    "(2) \\d \\[답변]digit 를 표현하며 숫자를 의미\n",
    "<br>\n",
    "(3) \\D \\[답변]non digit 를 표현하며 숫자가 아닌 것\n",
    "<br>\n",
    "(4) \\s \\[답변]space를 표현하며 공백 문자가 아닌 것\n",
    "<br>\n",
    "(5) \\S \\[답변]non space를 표현하며 공백 문자가 아닌 것\n",
    "<br>\n",
    "(6) \\w \\[답변]word 를 표현하며 알파벳 + 숫자 + _ 중의 한 문자\n",
    "<br>\n",
    "(7) \\W \\[답변]non word를 표현하며 알파벳 + 숫자 + _ 가 아닌 문자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) 정규표현식 모듈 함수 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 출력 결과 : \\['010', '1234', '5678', '25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['010', '1234', '5678', '25']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = \"\"\"이름 : 눈송이\n",
    "전화번호 : 010-1234-5678\n",
    "나이 : 25\n",
    "성별 : 여\"\"\" \n",
    "re.findall(\"\\d+\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 출력 결과 : \\['1234', '5678']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1234', '5678']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = \"\"\"이름 : 눈송이\n",
    "전화번호 : 010-1234-5678\n",
    "나이 : 25\n",
    "성별 : 여\"\"\" \n",
    "re.findall(\"\\d{4}\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 출력 결과 : \\['John', 'James', 'Noonsong'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John', 'James', 'Noonsong']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = \"\"\"100 John    PROF\n",
    "101 James   STUD\n",
    "102 Noonsong   STUD\"\"\" \n",
    "re.findall('[A-Z][a-z]+', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 정수 인코딩(Integer Encoding)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 문장 분리 및 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 셀은 실행만 시키면 됩니다.\n",
    "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\"\n",
    "# 문장 분리\n",
    "sentences = text.replace(\"!\", \".\").split(\". \")\n",
    "# 토큰화\n",
    "tokenized = [sentence.lower().split() for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 각 단어에 대한 빈도수 딕셔너리 저장  \n",
    "\\[출력] \\[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain.', 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain.', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 각 단어에 대한 빈도수 딕셔너리로 저장 \n",
    "# *stopword는 제거\n",
    "from nltk.corpus import stopwords\n",
    "vocab = {}\n",
    "stop_words = set(stopwords.words('english'))\n",
    "sentences = []      # stopword 제거된 토큰화된 문장 리스트 저장\n",
    "# 여기부터 코드 작성\n",
    "for sentences in tokenized:\n",
    "    result=[]\n",
    "    for word in sentences:\n",
    "        if word not in stop_words:\n",
    "            result.append(word)\n",
    "            if word not in vocab:\n",
    "                vocab[word]=0\n",
    "            vocab[word]+=1\n",
    "    sentences.append(result)\n",
    "# 빈도수 높은 순으로 정렬\n",
    "# 여기부터 코드 작성\n",
    "vocab_sorted=sorted(vocab.items(), key=lambda x:x[1], reverse=True)\n",
    "print(vocab_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) 빈도순으로 정렬된 단어에 정수 인덱스 부여  \n",
    "\\[출력] \\[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain.': 13, 'OOV': 14}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "i = 1\n",
    "# 여기부터 코드 작성\n",
    "for(word, frequency) in vocab_sorted:\n",
    "    word_to_index[word]=i\n",
    "    i=i+1\n",
    "# dictionary에 없는 단어\n",
    "word_to_index['OOV'] = len(word_to_index) + 1\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) word_to_index를 사용하여 sentences의 모든 단어들을 맵핑되는 정수로 인코딩  \n",
    "\\[출력] \\[\\[1, 5], \\[1, 8, 5], \\[1, 3, 5], \\[9, 2], \\[2, 4, 3, 2], \\[3, 2], \\[1, 4, 6], \\[1, 4, 6], \\[1, 4, 2], \\[7, 7, 3, 2, 10, 1, 11], \\[1, 12, 3, 13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14, 14, 14], [14, 14, 14, 14, 14, 14], [14, 14, 14, 14], [14, 14], [14], [14, 14, 14, 14], [14, 14, 14, 14, 14, 14, 14, 14, 14], [1, 12, 3, 13]]\n"
     ]
    }
   ],
   "source": [
    "encoded = []\n",
    "for s in sentences:\n",
    "    temp = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            temp.append(word_to_index[w])\n",
    "        except KeyError:\n",
    "            temp.append(word_to_index['OOV'])\n",
    "    encoded.append(temp)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 패딩(Padding)  \n",
    "0으로 패딩해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 가장 긴 문장 길이 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(sentence)for sentence in encoded) # 가장 긴 문장 길이 찾기\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 가장 긴 문장 길이에 맞춰 0으로 채워넣기  \n",
    "\\[\\[ 1  5  0  0  0  0  0]  \n",
    " \\[ 1  8  5  0  0  0  0]  \n",
    " \\[ 1  3  5  0  0  0  0]  \n",
    " \\[ 9  2  0  0  0  0  0]  \n",
    " \\[ 2  4  3  2  0  0  0]  \n",
    " \\[ 3  2  0  0  0  0  0]  \n",
    " \\[ 1  4  6  0  0  0  0]  \n",
    " \\[ 1  4  6  0  0  0  0]  \n",
    " \\[ 1  4  2  0  0  0  0]  \n",
    " \\[ 7  7  3  2 10  1 11]  \n",
    " \\[ 1 12  3 13  0  0  0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14 14 14  0  0  0  0  0  0]\n",
      " [14 14 14 14 14 14  0  0  0]\n",
      " [14 14 14 14  0  0  0  0  0]\n",
      " [14 14  0  0  0  0  0  0  0]\n",
      " [14  0  0  0  0  0  0  0  0]\n",
      " [14 14 14 14  0  0  0  0  0]\n",
      " [14 14 14 14 14 14 14 14 14]\n",
      " [ 1 12  3 13  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for sentence in encoded:\n",
    "    while len(sentence) < max_len: \n",
    "        sentence.append(0)\n",
    "\n",
    "encoded = np.array(encoded)        # 지금은 보기 좋게 하기 위함임..\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 원-핫 인코딩(One-Hot Encoding)  \n",
    "\\[출력] \\[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(word, word_to_index):\n",
    "    # 아래 pass 지우고 여기부터 코드 작성\n",
    "    one_hot_vector=[0]*(len(word_to_index))\n",
    "    index=word_to_index[word]\n",
    "    one_hot_vector[index]=1\n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 함수와 정수 인코딩 실행 후 실행할 것.\n",
    "one_hot_encoding(\"huge\", word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Bag of Words(BoW)  \n",
    "\\[답변] 단어들의 출현 빈도에만 집중하는 텍스트데이터 수치화 표현방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 텍스트 분석 전처리 경험해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 본인이 좋아하는 노래 가사, 시 등 text에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I'm mad at Disney Disney They tricked me tricked me Had me wishing on a shooting star.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer 사용해보셔도 됩니다.\n",
    "# Tokenizer 사용 시 시간이 좀 걸리기 때문에 그냥 띄어쓰기 기준으로 나눴습니다,\n",
    "text = text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['i','me','on','a','they']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 빈도수 리스트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"i'm\": 1, 'mad': 1, 'at': 1, 'disney': 2, 'tricked': 2, 'had': 1, 'wishing': 1, 'shooting': 1, 'star.': 1}\n"
     ]
    }
   ],
   "source": [
    "word_dict = {}\n",
    "# 코드 작성\n",
    "for word in text:\n",
    "    word=word.lower()\n",
    "    if word not in stopwords:\n",
    "        if word not in word_dict:\n",
    "            word_dict[word]=0\n",
    "        word_dict[word]+=1\n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 워드 클라우드 이미지 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-5254ad15ea2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# word_dict 를 이용해 wordcloud 만들기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 코드 작성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwordcloud\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "# word_dict 를 이용해 wordcloud 만들기\n",
    "# 코드 작성\n",
    "wordcloud=WordCloud().generate_from_frequencies(word_dict)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
