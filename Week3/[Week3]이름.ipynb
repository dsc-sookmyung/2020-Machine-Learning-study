{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1601437860599",
   "display_name": "Python 3.8.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "015647790a1949f0de812177e087b03d3c60d82f9d1707049480c8e3ba6333b1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# \\[Week3] 텍스트분석 기초"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. 텍스트 분석 기본 용어 정리\n",
    "https://wikidocs.net/21694  \n",
    "위의 링크와 구글링으로 정리  \n",
    "용어 정리는 추후에 본인이 보기에 편한 형식으로 정리하면 됩니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1. 토큰화 (Tokenization)  \n",
    "\\[답변] "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "2. 불용어 (Stopword)  \n",
    "\\[답변] "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "3. 정규표현식 (Regular Expression) 문법  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1) 정규 표현식에 해당하는 스트링 2개 이상  \n",
    "(1) a+  \n",
    "\\[답변]\n",
    "<br>\n",
    "(2) a{3}b{2,}  \n",
    "\\[답변]\n",
    "<br>\n",
    "(3) .+b$  \n",
    "\\[답변]\n",
    "<br>\n",
    "(4) ^ab*  \n",
    "\\[답변]\n",
    "<br>\n",
    "(5) \\[a-z]+\\[^a|z]  \n",
    "\\[답변]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "2) 정규 표현식 문자 규칙 의미  \n",
    "(1) \\\\\\ \\[답변]\n",
    "<br>\n",
    "(2) \\d \\[답변]\n",
    "<br>\n",
    "(3) \\D \\[답변]\n",
    "<br>\n",
    "(4) \\s \\[답변]\n",
    "<br>\n",
    "(5) \\S \\[답변]\n",
    "<br>\n",
    "(6) \\w \\[답변]\n",
    "<br>\n",
    "(7) \\W \\[답변]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "3) 정규표현식 모듈 함수 사용"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "(1) 출력 결과 : \\['010', '1234', '1234', '30']"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"\"\"이름 : 눈송이\n",
    "전화번호 : 010-1234-5678\n",
    "나이 : 25\n",
    "성별 : 여\"\"\" \n",
    "## 코드 작성"
   ]
  },
  {
   "source": [
    "(2) 출력 결과 : \\['1234', '5678']"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"\"\"이름 : 눈송이\n",
    "전화번호 : 010-1234-5678\n",
    "나이 : 25\n",
    "성별 : 여\"\"\"  \n",
    "# 코드 작성"
   ]
  },
  {
   "source": [
    "(3) 출력 결과 : \\['John', 'James', 'Noonsong'] "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"\"\"100 John    PROF\n",
    "101 James   STUD\n",
    "102 Noonsong   STUD\"\"\" \n",
    "# 코드 작성"
   ]
  },
  {
   "source": [
    "4. 정수 인코딩(Integer Encoding)  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1) 문장 분리 및 토큰화"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 셀은 실행만 시키면 됩니다.\n",
    "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\"\n",
    "# 문장 분리\n",
    "sentences = text.replace(\"!\", \".\").split(\". \")\n",
    "# 토큰화\n",
    "tokenized = [sentence.lower().split() for sentence in sentences]"
   ]
  },
  {
   "source": [
    "2) 각 단어에 대한 빈도수 딕셔너리 저장  \n",
    "\\[출력] \\[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain.', 1)]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 각 단어에 대한 빈도수 딕셔너리로 저장 \n",
    "# *stopword는 제거\n",
    "from nltk.corpus import stopwords\n",
    "vocab = {}\n",
    "stop_words = set(stopwords.words('english'))\n",
    "sentences = []      # stopword 제거된 토큰화된 문장 리스트 저장\n",
    "# 여기부터 코드 작성\n",
    "\n",
    "# 빈도수 높은 순으로 정렬\n",
    "# 여기부터 코드 작성\n",
    "\n",
    "print(vocab_sorted)"
   ]
  },
  {
   "source": [
    "3) 빈도순으로 정렬된 단어에 정수 인덱스 부여  \n",
    "\\[출력] \\[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_to_index = {}\n",
    "i = 1\n",
    "# 여기부터 코드 작성\n",
    "\n",
    "# dictionary에 없는 단어\n",
    "word_to_index['OOV'] = len(word_to_index) + 1\n",
    "print(word_to_index)"
   ]
  },
  {
   "source": [
    "4) word_to_index를 사용하여 sentences의 모든 단어들을 맵핑되는 정수로 인코딩  \n",
    "\\[출력] \\[\\[1, 5], \\[1, 8, 5], \\[1, 3, 5], \\[9, 2], \\[2, 4, 3, 2], \\[3, 2], \\[1, 4, 6], \\[1, 4, 6], \\[1, 4, 2], \\[7, 7, 3, 2, 10, 1, 11], \\[1, 12, 3, 13]]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded = []\n",
    "# 여기부터 코드 작성\n",
    "\n",
    "print(encoded)"
   ]
  },
  {
   "source": [
    "5. 패딩(Padding)  \n",
    "0으로 패딩해보기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1) 가장 긴 문장 길이 찾기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "7\n"
    }
   ],
   "source": [
    "max_len = # 가장 긴 문장 길이 찾기\n",
    "print(max_len)"
   ]
  },
  {
   "source": [
    "2) 가장 긴 문장 길이에 맞춰 0으로 채워넣기  \n",
    "\\[\\[ 1  5  0  0  0  0  0]  \n",
    " \\[ 1  8  5  0  0  0  0]  \n",
    " \\[ 1  3  5  0  0  0  0]  \n",
    " \\[ 9  2  0  0  0  0  0]  \n",
    " \\[ 2  4  3  2  0  0  0]  \n",
    " \\[ 3  2  0  0  0  0  0]  \n",
    " \\[ 1  4  6  0  0  0  0]  \n",
    " \\[ 1  4  6  0  0  0  0]  \n",
    " \\[ 1  4  2  0  0  0  0]  \n",
    " \\[ 7  7  3  2 10  1 11]  \n",
    " \\[ 1 12  3 13  0  0  0]]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 1  5  0  0  0  0  0]\n [ 1  8  5  0  0  0  0]\n [ 1  3  5  0  0  0  0]\n [ 9  2  0  0  0  0  0]\n [ 2  4  3  2  0  0  0]\n [ 3  2  0  0  0  0  0]\n [ 1  4  6  0  0  0  0]\n [ 1  4  6  0  0  0  0]\n [ 1  4  2  0  0  0  0]\n [ 7  7  3  2 10  1 11]\n [ 1 12  3 13  0  0  0]]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "for sentence in encoded:\n",
    "    # 아래 pass 지우고 코드 작성\n",
    "    pass\n",
    "\n",
    "encoded = np.array(encoded)        # 지금은 보기 좋게 하기 위함임..\n",
    "print(encoded)"
   ]
  },
  {
   "source": [
    "6. 원-핫 인코딩(One-Hot Encoding)  \n",
    "\\[출력] \\[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(word, word_to_index):\n",
    "    # 아래 pass 지우고 여기부터 코드 작성\n",
    "    pass\n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 위의 함수와 정수 인코딩 실행 후 실행할 것.\n",
    "one_hot_encoding(\"huge\", word_to_index)"
   ]
  },
  {
   "source": [
    "7. Bag of Words(BoW)  \n",
    "\\[답변]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. 텍스트 분석 전처리 경험해보기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1. 본인이 좋아하는 노래 가사, 시 등 text에 저장"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = # 좋아하는 문장들"
   ]
  },
  {
   "source": [
    "2. 토큰화"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer 사용해보셔도 됩니다.\n",
    "# Tokenizer 사용 시 시간이 좀 걸리기 때문에 그냥 띄어쓰기 기준으로 나눴습니다,\n",
    "text = text.split()"
   ]
  },
  {
   "source": [
    "3. 불용어 제거"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = # 본인이 생각하는 불용어 리스트 만들기"
   ]
  },
  {
   "source": [
    "4. 빈도수 리스트 만들기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "# 코드 작성"
   ]
  },
  {
   "source": [
    "5. 워드 클라우드 이미지 생성"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "# word_dict 를 이용해 wordcloud 만들기\n",
    "# 코드 작성"
   ]
  }
 ]
}