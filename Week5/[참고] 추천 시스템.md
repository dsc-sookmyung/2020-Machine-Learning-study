# 1. 자연어처리 - 문서 유사도 (용어 정리)

## 1. Bag of Words

[Bag-of-Words(BoW) 쉽게 이해하기 - 아무튼 워라밸](http://hleecaster.com/nlp-bag-of-words-concept/)

단어들의 **출현 빈도(frequency)**에만 집중하는 텍스트 데이터의 수치화 표현 방법

BoW의 가장 큰 문제점 : 단어의 순서를 무시 —> n-gram 등장

## 2. n-그램

**연속적**으로 n개의 token으로 구성된 것

# 2. 추천시스템

## 0. 추천시스템 종류 정리

[추천 시스템 (Recommendation System) 이란](https://medium.com/@john_analyst/%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9C-recommendation-system-%EC%9D%B4%EB%9E%80-111e315f8256)

### 1. Content-based filtering

### 2. Collaborative filtering

1) user-based collaborative filtering

2) item-based collaborative filtering

## 1. CSV 파일 불러와 Dataframe으로 저장

```python
movies = pd.read_csv("./tmdb_5000_movies.csv")
```

## 2. 전처리

### 1) 줄거리가 NaN인 영화 **drop**

```python
movies.dropna(axis=0, inplace=True)         # movies = movies.dropna(axis=0, inplace=False)
```

### 2) "overview" column 모두 소문자로, 문자 + 숫자 이외—> 띄어쓰기 대체

```python
import re
movies["overview"] = movies["overview"].apply(lambda x : re.sub("[\W]", " ", x.lower()))
```

## 3. TF-IDF

각 단어들마다 중요한 정도를 **가중치**로 주는 방법

문서의 유사도를 구하는 작업, 검색 시스템에서 검색 결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 사용

**1) tf(d,t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수**

**2) df(t) : 특정 단어 t가 등장한 문서의 수**

**3) idf(d, t) : df(t)에 반비례하는 수**

```python
from sklearn.feature_extraction.text import TfidfVectorizer
# ngram_range=(1, 2) 는 단어를 1개 혹은 2개 연속으로 보겠다
tfidf_vec = TfidfVectorizer(ngram_range=(1, 2))
tfidf_matrix = tfidf_vec.fit_transform(movies['overview'])
```

### 4. 영화 간 cosine 유사도

```python
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
plot_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)
similar_index = np.argsort(-plot_similarity)               # 유사도 높은 순으로 index 정렬
```
